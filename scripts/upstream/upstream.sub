#!/bin/bash

seed=47
sparsity=0.9

composer -m -n 4 upstream.train \
  --wandb_project_name upstream-bert-base \
  --model_name_or_path bert-base-uncased \
  --dataset_name bookcorpus \
  --dataset_name_2 wikimedia/wikipedia \
  --dataset_config_name_2 20231101.en \
  --max_seq_length 512 \
  --preprocessing_num_workers 128 \
  --precision amp_fp16 \
  --max_duration 5ep \
  --per_device_train_batch_size 64 \
  --per_device_train_microbatch_size 64 \
  --learning_rate 5e-4 \
  --alpha_f 0.01 \
  --sigma0 1e-10 \
  --sigma1 0.01 \
  --lambda_mix 1e-1 \
  --alpha_i_lambda_mix 1.0 \
  --alpha_f_lambda_mix 0.001 \
  --initial_warmup_steps 2ep \
  --sparse_finetune_steps 0ep \
  --pruning_interval 200 \
  --seed ${seed} \
  --initial_sparsity 0.3 \
  --final_sparsity ${sparsity} \
  --run_name ${sparsity}_${seed} \
  --save_folder ./checkpoints/upstream/${sparsity}/${seed} \
  --save_interval 1ep \
  --eval_interval 1dur \
  --log_interval 2000 \
  --autoresume
